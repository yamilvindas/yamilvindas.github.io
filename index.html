<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Yamil Vindas Yassine - Postdoctoral Researcher</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
        }
        header {
            background-color: #333;
            color: #fff;
            padding: 20px 0;
            text-align: center;
        }
        nav {
            text-align: center;
            padding: 10px 0;
            background-color: #444;
        }
        nav a {
            color: #fff;
            text-decoration: none;
            margin: 0 10px;
        }
        nav a:hover {
            text-decoration: underline;
        }
        section {
            padding: 20px;
        }
        h2 {
            color: #333;
        }
        p {
            line-height: 1.6;
            color: #555;
        }
        footer {
            background-color: #333;
            color: #fff;
            text-align: center;
            padding: 10px 0;
            position: fixed;
            bottom: 0;
            width: 100%;
        }
    </style>
</head>
<body>
    <header>
        <h1>Yamil Vindas Yassine</h1>
        <img src="https://raw.githubusercontent.com/yamilvindas/yamilvindas.github.io/main/Photo.jpeg" alt="Photo" width="178" height="150">
        <h2>Research Topics</h2>
    </header>
    <section>
        <h1>Short Bio</h1>
        <p>
          I am a post-doctoral fellow at the French Institute for Research in Computer Science and Automation in Lyon, France. My current research focuses on applying deep learning methods to wireless communications and the medical field. Specifically, I am interested in self-supervised online learning techniques for wireless channel charting, semi-supervised learning approaches for data annotation and classification, and the characterization of transcranial Doppler monitoring signals for stroke prevention.
        </p>
        <h1>Research Interests</h1>
        <p>
          Deep Learning, Machine Learning, Self-supervised learning,  Semi-supervised learning, Artificial Intelligence, Model Compression, Medical Imaging, Telecommunications.
        </p>
        <h1>Publications</h1>
        <h2> Journals </h2>
        <p>
            <a href="https://hal.science/hal-04652637">Vindas, Y., Guépié, B.K., Almar, M., Roux, E., and Delachartre, P., 2024. Trainable pruned ternary quantization for medical signal classification models, in Neurocomputing.</a>
        </p>
        
        <p>
            <a href="https://www.creatis.insa-lyon.fr/~vindas/Papers/Vindas%20et%20al.%20-%202023%20-%20An%20asymmetric%20heuristic%20for%20trained%20ternary%20quantization%20based%20on%20the%20weights%20statistics.pdf">Vindas, Y., Guépié, B.K., Almar, M., Roux, E., and Delachartre, P., 2024. An asymmetric heuristic for trained ternary quantization based on the statistics of the weights: an application to medical signal classification (in review)</a>
        </p>
        
        <p>
            <a href="https://www.creatis.insa-lyon.fr/~vindas/Papers/Vindas%20et%20al.%20-%202023%20-%20Guided%20deep%20embedded%20clustering%20regularization%20for%20multifeature%20medical%20signal%20classification.pdf">Vindas, Y., Roux, E., Guépié, B.K., Almar, M., and Delachartre, P., 2023. Guided deep embedded clustering regularization for multifeature medical signal classification, in Pattern Recognition.</a>
        </p>
        <p>
            <a href="https://www.creatis.insa-lyon.fr/~vindas/Papers/Vindas%20et%20al.%20-%202022%20-%20Semi-automatic%20data%20annotation%20based%20on%20feature-space%20projection%20and%20local%20quality%20metrics:%20an%20application%20to%20cerebral%20emboli%20characterization.pdf">Vindas, Y., Guépié, B.K., Almar, M., Roux, E., and Delachartre, P., 2022. Semi-automatic data annotation based on feature-space projection and local quality metrics: an application to cerebral emboli characterization, in Medical Image Analysis, page 102437, 2022. ISSN 1361-8415. doi: https://doi.org/10.1016/j.media.2022.102437.</a>
        </p>
        <h2> Conferences with proceedings </h2>
        <p>
            <a href="https://hal.science/hal-04685466">Vindas, Y., Guillaud, M., 2024. Multi-Site Wireless Channel Charting Through Latent Space Alignment, in: 2024 IEEE International Workshop on Signal Processing Advances in Wireless Communications (SPAWC).</a>
        </p>
        <p>
            <a href="https://www.creatis.insa-lyon.fr/~vindas/Papers/Vindas%20et%20al.%20-%202023%20-%20Soft-labels%20noise%20tolerant%20loss%20functions%20for%20transcranial%20Doppler%20ultrasound%20signal%20classification.pdf">Vindas, Y., Guépié, B.K., Almar, M., Roux, E.,  Delachartre, P., 2023. Soft-labels noise tolerant loss functions for transcranial Doppler ultrasound signal classification, in: 2023 IEEE International Ultrasonics Symposium (IUS).</a>
        </p>
        <p>
            <a href="https://www.creatis.insa-lyon.fr/~vindas/Papers/Vindas%20et%20al.%20-%202022%20-%20Deep%20Embedded%20Clustering%20regularization%20for%20imbalanced%20cerebral%20emboli%20classification%20using%20transcranial%20Doppler%20ultrasound%20(Submitted).pdf">Vindas, Y., Roux, E., Guépié, B.K., Almar, M.,  Delachartre, P., 2023 Deep Embedded Clustering regularization for imbalanced cerebral emboli classification using transcranial Doppler ultrasound, in: 2023 European Signal Processing Conference (EUSIPCO) </a>
        </p>
        <p>
            <a href="https://www.creatis.insa-lyon.fr/~vindas/Papers/Vindas%20et%20al.%20-%202022%20-%20An%20hybrid%20CNN-Transformer%20model%20based%20on%20multi-feature%20extraction%20and%20attention%20fusion%20mechanism%20for%20cerebral%20emboli%20classification.pdf">Vindas, Y., Guépié, B.K., Almar, M., Roux, E., and Delachartre, P., 2022. An hybrid CNN-Transformer model based on multi-feature extraction and attention fusion mechanism for cerebral emboli classification,  in: MLHC. 05–06 Aug 2022, PMLR.</a>
        </p>
        <p>
            <a href="https://www.creatis.insa-lyon.fr/~vindas/Papers/Vindas%20et%20al.%20-%202021%20-%20Semi-supervised%20annotation%20of%20Transcranial%20Doppler%20ultrasound%20micro-embolic%20data.pdf">Vindas, Y., Roux, E., Guépié, B.K., Almar, M.,  Delachartre, P., 2021. Semi-supervised annotation of transcranial Doppler ultrasound micro-embolic data, in: 2021 IEEE International  Ultrasonics Symposium (IUS), pp. 1–4.  doi:10.1109/IUS52206.2021.9593847.</a>
        </p> 
        <h2> Conferences without proceedings </h2>
          <p>
              <a href="https://www.creatis.insa-lyon.fr/~vindas/Papers/Vindas%20et%20al.%20-%202023%20-%20Classification%20multi-repr%c3%a9sentation%20d'emboles%20c%c3%a9r%c3%a9braux%20%c3%a0%20partir%20d'un%20dispositif%20de%20Doppler%20transcr%c3%a2nien.pdf"> Vindas, Y., Guépié, B.K., Almar, M., Roux, E., and Delachartre, P., 2023. Classification multi-représentation d'emboles cérébraux à partir d'un dispositif de Doppler transcrânien. in:2023 Intelligence Artificielle en Imagerie Biomédicale (IABM).<a>
          </p>
        <h1>Teaching</h1>
        <p>
          2020-2024: Mathematical and Software Tools 1, IUT Gratte  Ciel Lyon 1 (first year students).
        </p>
        <p>
          2020-2022: Algorithmics and Programming, INSA Lyon (second year students).
        </p>
        <p>
          2022-2023: Data Science, Faculté Médecine Lyon Est (first year students).
        </p>
        <p>
          2021 and 2022: Deep Learning for Medical Imaging School (hands-on sessions).
        </p>
        <p>
          Representative of Ph.D students of CREATIS at the computer science federation of Lyon (FIL), from 2021 to 2023.
        </p>
        <h1>Contact</h1>
        <p>
          INRIA Antenne Lyon la Doua, 56 Boulevard Niels Bohr, CS 52132, 69603 Villeurbanne.
        </p>
        <p>
          Email: yamil(dot)vindas-yassine(at)inria.fr
        </p>
    </section>
    <footer>
        &copy; 2024 Yamil Vindas Yassine. All rights reserved.
    </footer>
</body>
</html>
